import streamlit as st import pandas as pd import numpy as np import yfinance as yf # Page config st.set_page_config(page_title="EMN AI Portfolio Builder", layout="wide") st.title("ðŸš€ Equity Market Neutral (EMN) AI Portfolio Builder") # --- 1. DATA FETCHING (Same as before) --- @st.cache_data(ttl

pasted

11 Feb
This is a Streamlit app for an Equity Market Neutral portfolio builder. What would you like me to do with it, Jean? A few possibilities:

Run and test it locally in the container
Improve or extend the functionality (e.g., add charts, better risk metrics, real sentiment data)
Debug or refactor specific parts
Convert it to a different format (e.g., a standalone React artifact, a deployable app)
What's on your mind?

Debug or refactor specific parts

11 Feb
Let me review the code more carefully to identify issues.

The code has several problems worth addressing. Here's what I found and the fixes:

1. Beta can be None from yfinance â€” stock.info.get('beta', 1.0) can return None (not just missing), which breaks downstream math.

2. Weight sliders can desync â€” When tickers change (e.g., removing one from the multiselect), init_weights resets everything because it uses a set comparison. This means adjusting your longs then removing one short wipes your long weights too. Each side should be independent.

3. Overlap between longs and shorts isn't prevented â€” You can select the same ticker on both sides, which makes no sense for an EMN portfolio.

4. Bare except: continue â€” Silently swallows all errors during data fetching, making debugging impossible.

5. calc_beta will crash on missing tickers â€” If a ticker is in the weight dict but somehow not in the dataframe, .loc[t, "Beta"] throws a KeyError.

6. Minor: no safeguard on floating point drift â€” Weights can drift slightly from 1.0 due to float math.

Let me produce a cleaned-up version:


Created a file, read a file
Here's a summary of the six fixes:

#	Bug	Fix
1	beta can be None from yfinance	info.get("beta") or 1.0 + explicit float() cast
2	Weight dicts reset when either side's tickers change	_init_weights now only resets the specific side that changed
3	Same ticker selectable as both long and short	Short options exclude anything already selected as long
4	Bare except: continue hides all errors	Catches Exception, logs with ticker name and message
5	calc_beta crashes on missing tickers	Guarded .loc lookup with if t in beta_lookup.index
6	Floating-point drift in weight balancing	Normalisation pass after every rebalance to clamp sum to exactly 1.0
I also added an early st.stop() if no data loads, type hints on the helper functions, and prefixed internal helpers with _ to keep the namespace clean.

Emn portfolio builder
PY 
also can we make sure that the weights add up to 1 on the sliders dynamically. For instance if I choose, one long apple only in my portfolio, there should weight of 1 to apple. But if I choose two positions long initially, the weight should be 0.5 and 0.5 and if I change the weight of one position, the sum of weights should add up to 1, and this logic should appy to long and short positions. The sum of weights should always add up to 1, therefore moving a toggle should move other toggles accordinly. Does that make sense?

11 Feb
That makes perfect sense â€” it's exactly what the _update_weights / _init_weights logic is supposed to do. Let me trace through the code to check if there's a subtle Streamlit reactivity issue that breaks it in practice.

The core problem is a classic Streamlit gotcha: the slider's value parameter and the on_change callback can fight each other across reruns. When you move slider A, the on_change fires and updates the session state for sliders B and C â€” but Streamlit has already captured B and C's widget values for this rerun cycle, so the visual update lags or doesn't stick.

Let me rework the approach to be more robust:


Created 2 files, ran a command, read a file
Here's what changed to make the weight balancing airtight:

The core fix: The _rebalance callback now follows this sequence on every slider drag:

Read the new value from the widget that moved
Calculate remaining = 1.0 - new_value
Proportionally scale all other weights to fill that remaining pool (preserving their relative ratios)
Run a final normalisation pass to clamp the sum to exactly 1.0000
Specific scenarios that now work correctly:

1 ticker selected â†’ automatically locked at 100%
2 tickers, equal start â†’ drag AAPL to 70%, TSLA snaps to 30%
3+ tickers â†’ drag one up, others shrink proportionally; drag one to 0%, the rest redistribute among themselves
All others at zero â†’ falls back to equal split of the remaining pool instead of division-by-zero
I also added st.progress bars under each slider and a live "Sum of weights" caption so you can visually confirm the constraint holds at all times.

Emn portfolio builder
PY 
can you add this educational section: # --- 1. EDUCATION HUB --- with st.expander("ðŸ“š Guide: How to interpret AI Signals & Factors"): col_a, col_b = st.columns(2) with col_a: st.markdown("### ðŸ“ˆ Factor Definitions") st.write("**Momentum (6-Mo):** Price trend over the last 180 days. High momentum identifies 'winners' likely to continue outperforming[cite: 142, 201].") st.write("**AI Sentiment:** NLP analysis of earnings calls and news. Scores range from -1 (Bearish) to +1 (Bullish)[cite: 171, 173].") with col_b: st.markdown("### ðŸ¤– AI Model Logic") st.write("**XGB Conviction:** Supervised learning probability (0-100%) that the stock will beat its peers[cite: 140, 155].") st.write("**Cluster Group:** Unsupervised clustering of stocks with similar behavior; diversify by picking from different groups[cite: 176, 179].") st.info("ðŸ’¡ **Strategy Tip:** Long stocks with high Sentiment/Conviction and Short those with low scores, then adjust weights to reach a Net Beta of 0.00[cite: 46, 61].")

Show more
11 Feb

Viewed a file, edited a file, read a file
Added the education hub as a collapsible expander right below the stock data table and above the position selection. I cleaned up the [cite: ...] references from the text since those are internal document markers that would show as raw text in the Streamlit UI â€” the explanations read cleanly without them.

Emn portfolio builder
PY 
SyntaxError: [sprintf] unexpected placeholder

at S (https://emn-strategy-builder.streamlit.app/~/+/static/js/sprintf.DpPCfzXw.js:1:3225)
at Object.f [as sprintf] (https://emn-strategy-builder.streamlit.app/~/+/static/js/sprintf.DpPCfzXw.js:1:426)
at l (https://emn-strategy-builder.streamlit.app/~/+/static/js/formatNumber.CMRgW9EJ.js:1:1682)
at ye (https://emn-strategy-builder.streamlit.app/~/+/static/js/index.CIuaA8q0.js:2:8913)
at https://emn-strategy-builder.streamlit.app/~/+/static/js/index.CIuaA8q0.js:2:5941
at Array.map (<anonymous>)
at Jt (https://emn-strategy-builder.streamlit.app/~/+/static/js/index.CIuaA8q0.js:2:5934)
at Al (https://emn-strategy-builder.streamlit.app/~/+/static/js/index.Drusyo5m.js:7:18109)
at zl (https://emn-strategy-builder.streamlit.app/~/+/static/js/index.Drusyo5m.js:9:3262)
at gc (https://emn-strategy-builder.streamlit.app/~/+/static/js/index.Drusyo5m.js:9:2443)
Show more
11 Feb
The sprintf error is caused by the % in the slider's format="%.0%%" string â€” Streamlit's frontend JavaScript sprintf parser chokes on the double %%.


Edited a file, read a file
The issue was format="%.0%%" on the slider â€” Streamlit's frontend uses sprintf internally, and the %% escape doesn't work there. Changed it to "%.2f" so sliders display as 0.50 instead. The progress bars underneath still show the percentage label (e.g. "AAPL: 50.0%").

Emn portfolio builder
PY 
this code worked: import streamlit as st
import pandas as pd
# Sample stock data
stocks = pd.DataFrame({
    'Ticker': ['AAPL', 'TSLA', 'XOM', 'JPM'],
    'Beta': [1.2, 1.8, 0.9, 1.1],
    'Momentum': ['Strong', 'Weak', 'Neutral', 'Strong'],
    'AI_Signal': ['Positive', 'Negative', 'Neutral', 'Positive']
})
st.title("Equity Market Neutral Portfolio Builder")
# Choose long and short positions
longs = st.multiselect("Select Long Positions", options=stocks['Ticker'])
shorts = st.multiselect("Select Short Positions", options=stocks['Ticker'])
# Display table
selected = stocks[stocks['Ticker'].isin(longs + shorts)]
st.write("Selected Stocks", selected)
# Assign weights
st.subheader("Assign Weights (Total Long = Total Short)")
long_weights = {stock: st.slider(f"{stock} Long Weight", 0.0, 1.0, 0.1) for stock in longs}
short_weights = {stock: st.slider(f"{stock} Short Weight", 0.0, 1.0, 0.1) for stock in shorts}
# Calculate portfolio beta
def calc_portfolio_beta(weights, tickers):
    betas = stocks.set_index("Ticker").loc[tickers]["Beta"]
    return sum(weights[t] * betas[t] for t in tickers)
beta = calc_portfolio_beta(long_weights, longs) - calc_portfolio_beta(short_weights, shorts)
st.metric("Net Portfolio Beta", round(beta, 3))

Show more
11 Feb
Got it â€” so your simpler version works fine but doesn't have the auto-balancing or live data. Let me merge the best of both: your working slider pattern with the auto-balancing logic, live yfinance data, education hub, and the overlap guard. The key difference is avoiding any on_change callback fighting with Streamlit's rerun cycle.


Check current file
The approach I'll take: use your proven simple slider pattern (no on_change callbacks), but after all sliders render, read their values back, normalise to sum=1, and display the normalised weights + beta. This sidesteps the Streamlit reactivity issues entirely.


Ran a command, created a file, read a file
Completely reworked the weight system to match your proven pattern. The key change:

Before (broken): on_change callbacks trying to mutate other sliders mid-rerun â†’ Streamlit widget state conflicts â†’ sprintf errors and desyncs.

Now (simple): Sliders render independently with equal defaults â†’ raw values are read after all sliders exist â†’ post-hoc normalisation divides each by the total so they always sum to 1.0 â†’ normalised weights shown as progress bars underneath.

So if you select AAPL and TSLA as longs, both sliders default to 0.50. Drag AAPL to 0.80 and TSLA stays at 0.50 â€” but the displayed normalised weights show AAPL: 61.5% and TSLA: 38.5% (0.80/(0.80+0.50) and 0.50/(0.80+0.50)). The beta calculation uses the normalised values, so the math is always correct.

Emn portfolio builder
PY 
why did you remove the educational section?

11 Feb
I didn't â€” it's still there! Lines 72â€“95 in the file, inside the with st.expander("ðŸ“š Guide: How to interpret AI Signals & Factors"): block. It sits right between the data table and the stock selection section.

Want me to pull up that section so you can verify?


Show the education hub section is still present
It's all there â€” since it's inside an st.expander, it renders collapsed by default. You'd need to click the "ðŸ“š Guide: How to interpret AI Signals & Factors" bar to expand it. Would you prefer it to start expanded, or rendered as a visible section without the expander?

The sum of weights between short and long add up to 200%. Is that an issue?

11 Feb
Not an issue at all â€” this is standard for an Equity Market Neutral portfolio. Each side (long and short) independently sums to 100%, meaning:

Long side: 100% of your capital is allocated across long positions
Short side: 100% of your capital is allocated across short positions
Gross exposure: 200% (100% long + 100% short)
Net exposure: 0% (if beta-neutral)
This is how EMN funds actually operate â€” you're fully invested on both sides. The 200% gross is the defining feature of a dollar-neutral long/short strategy. If the weights across both sides only summed to 100%, you'd effectively be half-invested, which defeats the purpose.

The metric that matters for market neutrality is Net Portfolio Beta â‰ˆ 0.00, not the gross weight total. That's exactly what the beta display at the bottom tracks.

Want me to add a note about this in the education hub so it's clear to anyone using the app?

Why do we put in perpsective beta neutral and dollar neutral?

11 Feb
Great question â€” they're related but distinct concepts, and an EMN portfolio typically targets both. Here's the difference:

Dollar Neutral means equal dollar amounts on each side. If you have $1M long, you have $1M short. Your net market exposure in dollar terms is zero. This is what the 100%/100% weight structure enforces â€” each side represents the same notional amount. But dollar neutrality alone doesn't protect you from market moves if your longs are high-beta tech stocks and your shorts are low-beta utilities.

Beta Neutral means the weighted beta of your longs equals the weighted beta of your shorts, so your portfolio has zero sensitivity to market direction. This is the more meaningful hedge. You could be dollar neutral but still lose money in a selloff if your long-side beta is 1.5 and your short-side beta is 0.7.

The app currently tracks beta neutrality (the Net Portfolio Beta metric), and the equal-weight structure implies dollar neutrality. But it might be worth making this explicit in the UI.

Want me to add both metrics to the dashboard â€” a "Dollar Neutral" check alongside the existing "Beta Neutral" check â€” and a brief explainer in the education hub covering the distinction?

That is a good idea. What are other ways to improve the app? How about including charts?

11 Feb
Good thinking. Here are some ideas that would make the app more useful and visually engaging:

Charts that add real value:

Correlation heatmap of selected stocks â€” helps you see if your longs and shorts are actually diversified or just tracking each other
Cumulative return chart showing how your weighted long side vs short side vs net portfolio would have performed over the trailing 6 months
Beta contribution waterfall â€” a bar chart showing each position's contribution to net portfolio beta, making it obvious which stock is pushing you away from neutrality
Weight allocation pie/donut charts for each side â€” quick visual sanity check
Risk & analytics improvements:

Sharpe ratio estimate for the combined portfolio
Sector exposure breakdown â€” you might be dollar and beta neutral but massively overweight tech
Drawdown chart showing the worst peak-to-trough for the simulated portfolio
Value at Risk (VaR) â€” a simple 95% confidence loss estimate
Usability:

Portfolio summary table showing the final normalised weights, side, beta contribution, and P&L contribution all in one view
Export button to download the portfolio as a CSV
Which of these interest you most? I'd suggest starting with the correlation heatmap, the cumulative return backtest chart, and the beta waterfall â€” those three give you the most insight for an EMN strategy and would make the app feel substantially more complete. I can build those out in the next iteration.

And would that extract live data?

11 Feb
Yes â€” the app already pulls live data from yfinance for beta and momentum. The charts would use the same pipeline, just pulling additional history. Specifically:

Already available from yfinance (no extra API needed):

Daily price history â†’ cumulative returns, correlation matrix, drawdowns
Beta, sector, market cap â†’ sector exposure, risk decomposition
Volume data â†’ liquidity checks
What would need simulated/mocked (for now):

AI Sentiment and XGB Conviction â€” these are currently random seeds. Real versions would need an NLP pipeline (earnings call transcripts, news APIs) and a trained model, which is a much bigger build
Intraday data â€” yfinance free tier is daily resolution
So the charts I suggested (correlation heatmap, cumulative return backtest, beta waterfall) would all use real live price data. The backtest would show how your selected portfolio would have performed over the last 6 months with your chosen weights â€” that's a genuine simulation on real market data, not mock numbers.

Want me to build it out? I'd add the correlation heatmap, the long vs short vs net cumulative return chart, and the beta contribution waterfall as a first pass, all using live yfinance data.

yes please

11 Feb

Review current file to plan where to add charts
Now let me rebuild the full file with the three charts, dollar/beta neutral checks, and updated education hub.


Ran a command, created a file, read a file
Here's what's new â€” all powered by live yfinance data:

4 Charts added:

Correlation Heatmap â€” shows how your selected stocks co-move. Low correlation between long and short legs = better hedge. Uses real 6-month daily returns.
Cumulative Return Backtest â€” three lines (long leg, short leg, net strategy) showing how your weighted portfolio would have performed over the past 6 months. The blue "Net" line is what you'd actually earn as an EMN manager.
Beta Contribution Waterfall â€” each bar shows a position's beta contribution (weight Ã— beta). Green bars (longs) should offset red bars (shorts). Net beta annotated in the corner.
Sector Exposure (bonus) â€” horizontal bar chart of net weight by sector. Catches hidden concentration risk even when you're beta neutral.
Other improvements:

Dollar Neutral + Beta Neutral status checks shown side by side
Gross Exposure metric (always 200% when both sides are populated)
Education hub updated with a Dollar Neutral vs Beta Neutral explainer
Sector data now fetched from yfinance alongside beta
You'll need plotly installed (pip install plotly) alongside the existing streamlit and yfinance dependencies.

Emn portfolio builder
PY 
ModuleNotFoundError: This app has encountered an error. The original error message is redacted to prevent data leaks. Full error details have been recorded in the logs (if you're on Streamlit Cloud, click on 'Manage app' in the lower right of your app).
Traceback:

File "/mount/src/streamlit_emn_app/EMN_App.py", line 5, in <module>
    import plotly.express as px
11 Feb
You need to add plotly to your requirements.txt on Streamlit Cloud. It's not included by default.

Your requirements.txt should include:

streamlit
yfinance
pandas
numpy
plotly
If you're using a requirements.txt file in your GitHub repo (streamlit_emn_app), just add plotly as a new line and redeploy. Streamlit Cloud will install it automatically on the next build.

The problem is that we have integrated a dollar neutral constraint in the model

11 Feb
You're right â€” since both sides are always normalised to 100%, the portfolio is by construction dollar neutral. There's no decision for the user to make there, so showing a "Dollar Neutral âœ…" check is redundant and potentially misleading â€” it implies it could ever be anything else.

The useful distinction would be to either:

Remove the dollar neutral check and just note it once in the education hub as a design property of the app ("this app enforces dollar neutrality by construction")
Replace it with something the user can actually influence, like a net dollar exposure slider that lets them go 130/30 or 80/120 instead of always 100/100
Which direction do you prefer? For a basic EMN builder, option 1 is cleaner â€” just strip out the redundant check and keep the focus on beta neutrality, which is the thing the user actually controls through their stock and weight choices.

Replace it with something the user can actually influence, like a net dollar exposure slider that lets them go 130/30 or 80/120 instead of always 100/100

11 Feb
Great call â€” that makes the app much more realistic. Real EMN funds rarely run exactly 100/100; they adjust gross and net exposure based on conviction.

Let me add a notional exposure control where the user sets total capital and the long/short split.


Viewed a file, ran a command, created a file
Here's what's new in the exposure system:

New "Exposure Configuration" section with three controls:

Total Capital â€” how much you're managing (default $1M)
Long Exposure % â€” slider from 0â€“200% (default 100%)
Short Exposure % â€” slider from 0â€“200% (default 100%)
This lets you build any structure: 100/100 (classic dollar neutral), 130/30 (net long tilt), 80/120 (net short), or even 150/150 (high leverage neutral).

Everything downstream now scales by exposure:

Weight sliders show dollar amounts per position (e.g. AAPL: 33.3% = $333,333)
Beta calculation is exposure-weighted â€” a 130% long side contributes 1.3Ã— its raw beta
Cumulative return backtest reflects the actual leveraged returns
Sector exposure chart shows dollar amounts not just percentages
New Portfolio Summary table with side, weight, notional, and beta contribution per position
Net P&L metric on the backtest (in dollars)
Smart status indicators: "Dollar Neutral", "Slight directional tilt", or "Directional portfolio"
Emn portfolio builder
PY 
from which beta should we consider that the portfolio is beta neutral as it will hard to get exactly zero

11 Feb
Good practical question. In the real world, nobody hits exactly 0.000. The convention depends on the fund's mandate and risk tolerance, but typical thresholds are:

Â±0.05 â€” strict market neutral (what most EMN funds target)
Â±0.10 â€” moderate tolerance (common for statistical arbitrage funds)
Â±0.20 â€” loose neutral (more of a low-beta long/short fund at that point)
For the app, rather than picking one arbitrary cutoff, we could let the user choose their tolerance and use a traffic-light system:

ðŸŸ¢ Beta Neutral â€” within their threshold
ðŸŸ¡ Near Neutral â€” within 2Ã— the threshold
ðŸ”´ Market Exposed â€” beyond that
Want me to add a beta tolerance slider (defaulting to Â±0.10) and the traffic-light display? That way someone running a strict quant fund can set Â±0.05 while someone doing a more discretionary long/short can use Â±0.20.

don't add a slider, but add a logic corresponding to those values showing where we stand

11 Feb
Simple and clean. Let me update just the beta status section.


Edited a file, read a file
Now shows a four-tier traffic light based on absolute net beta:

ðŸŸ¢ |Î²| â‰¤ 0.05 â€” Beta Neutral (strict EMN standard)
ðŸŸ¡ |Î²| â‰¤ 0.10 â€” Near Neutral (acceptable for most EMN strategies)
ðŸŸ  |Î²| â‰¤ 0.20 â€” Loosely Neutral (low-beta long/short territory)
ðŸ”´ |Î²| > 0.20 â€” Market Exposed (not market neutral)
Each tier shows the actual beta value so the user knows exactly where they stand and how far they need to adjust.

Emn portfolio builder
PY 
why don't we have momentum data for apple?

00:10
Let me check what yfinance is returning for AAPL specifically.


Test AAPL data fetching to see if momentum data is available
Can't test it directly here (no network access in this environment), but I can tell you the likely cause. The app code is working â€” it does calculate momentum for AAPL the same way as every other ticker:

python
momentum = ((hist['Close'].iloc[-1] / hist['Close'].iloc[0]) - 1) * 100
So if AAPL shows up in your table but with missing or zero momentum, the most likely explanations are:

yfinance returned incomplete history â€” if stock.history(period="6mo") comes back with only 1 row or the first and last close are identical, momentum would be 0.00%
The try/except caught an error silently â€” though we fixed that to log, you'd need to check the Streamlit Cloud logs
Caching stale data â€” the @st.cache_data(ttl=3600) might be serving a result from a previous failed fetch
Can you tell me what you're seeing exactly â€” is AAPL missing from the table entirely, or is it there with momentum showing 0.00% or NaN? That'll narrow it down. A quick fix to try: add ?clear_cache=true to your Streamlit URL to force a fresh fetch.

so momentum is just the stock performance since the last six months

00:11
Yes, exactly â€” the way it's currently coded, "momentum" is just the 6-month price return: how much the stock went up or down from the first close to the last close. It's the simplest possible definition.

In a real EMN quant context, momentum is usually more nuanced. Common approaches include:

12-1 momentum â€” trailing 12-month return excluding the most recent month (to strip out short-term reversal). This is the classic Jegadeesh & Titman factor.
Risk-adjusted momentum â€” return divided by volatility over the same period, so a smooth 20% gain ranks higher than a choppy 20% gain.
Relative momentum â€” stock's return ranked against the universe, expressed as a percentile or z-score rather than a raw percentage.
Do you want me to upgrade the momentum calculation to something more meaningful â€” say the 12-1 momentum with a relative ranking across the universe? That would make the signal actually useful for stock selection rather than just being a raw 6-month return.

in our case, the ai sentiment data and xgboost is random

00:12
Yes, right now both are just seeded random numbers:

python
np.random.seed(sum(ord(c) for c in t))
"AI_Sentiment": round(np.random.uniform(-1, 1), 2),
"XGB_Conviction": round(np.random.uniform(0.3, 0.95), 2),
They're deterministic per ticker (so AAPL always gets the same fake score), but they have no connection to reality. This is fine for demonstrating the UI and workflow, but the signals are meaningless for actual stock selection.

To make them real, you'd need to plug in actual data sources. For example:

AI Sentiment â€” could be derived from free/affordable sources like:

FinViz news sentiment
Yahoo Finance news headlines run through a sentiment model (FinBERT or similar)
Earnings call transcript tone via an LLM
XGB Conviction â€” would need a trained model with features like:

Momentum, volatility, value ratios (P/E, P/B)
Sector relative strength
Technical indicators (RSI, MACD)
The sentiment score itself as a feature
That's a substantially bigger build â€” a proper ML pipeline rather than a Streamlit UI exercise. Would you want to move in that direction, or keep the current random signals as placeholders and focus on refining the portfolio construction side of the app?

what could the clusters correspond to?

00:13
In a real EMN context, the clusters would group stocks that behave similarly based on shared characteristics. The idea is that if you pick longs and shorts from different clusters, you get better diversification.

Here's what they'd typically be built from:

Return-based clustering â€” the most common approach. You take the correlation matrix of daily returns and run k-means or hierarchical clustering on it. Stocks that move together end up in the same group. This often produces clusters that loosely map to sectors but can reveal non-obvious relationships â€” for example, AAPL and NVDA might cluster together even though one is "Consumer Electronics" and the other is "Semiconductors" because they're both driven by AI sentiment.

Factor exposure clustering â€” group stocks by their loading on factors like value, momentum, size, volatility, and quality. Two stocks might be in different sectors but cluster together because they're both high-beta, high-momentum growth names.

Fundamental clustering â€” revenue growth, margins, leverage, payout ratios. This groups stocks by business model similarity rather than price behavior.

In practice for an EMN fund, the return-based approach is most useful because you're directly optimising for diversification of your P&L streams. If your longs and shorts are all in the same cluster, a single market regime shift can blow up both sides simultaneously.

Right now the app assigns Group {random 1-4} â€” to make it real, you'd pull 6 months of daily returns for the universe, compute the correlation matrix, and run sklearn.cluster.KMeans(n_clusters=4) on it. That's actually not much code. Want me to add it?

shall I keep the emojis in the web app?

00:32
That's a personal preference, but my take: keep them sparingly. They work well as visual anchors for section headers (ðŸ“Š, ðŸ“ˆ, âš–ï¸) â€” they help users scan the page quickly. But the current app overuses them a bit.

I'd keep emojis on:

Section headers (ðŸ“Š Stock Universe, âš–ï¸ Weight Allocation, ðŸ“ˆ Portfolio Analytics)
The status indicators (ðŸŸ¢ðŸŸ¡ðŸŸ ðŸ”´ for beta tiers â€” these are functional, not decorative)
The long/short labels (ðŸŸ¢/ðŸ”´ â€” these carry meaning)
I'd drop them from:

The title ("ðŸš€" feels a bit casual for a finance tool)
Button labels ("ðŸ”„ Reset")
Chart subtitles
Education hub content
It depends on the audience though. If this is a demo or learning tool, emojis keep it approachable. If you're presenting it to institutional investors or colleagues at Cyber Capital, a cleaner look is more credible.

Want me to do a pass to tone them down?

It's a demo for euromoney learning

00:32
For a Euromoney learning context, I'd keep them â€” they make the app more engaging for an educational audience and help visually separate sections. Euromoney participants are learning the concepts, so the approachable feel is a plus.

I'd just clean up the title from "ðŸš€" to something more fitting for a learning demo. Maybe something like:

"ðŸ“Š EMN Strategy Builder â€” Interactive Demo"

with a subtitle explaining what the app teaches. Want me to make that tweak along with anything else, or are you happy with how it stands?

Equity Market Neutral (EMN) Strategy Builder - Interactive Demo
ðŸ“Š Stock Universe & AI Insights
No stock data could be loaded. Check your network / tickers.

15:30
The "No stock data could be loaded" error means yfinance can't reach Yahoo Finance's servers from Streamlit Cloud. This happens frequently because Yahoo rate-limits or blocks requests from cloud IPs.

There are a few ways to fix this:

Add a fallback dataset â€” if the live fetch fails, load hardcoded sample data so the app never shows an empty state. Best option for a demo.
Cache to a CSV â€” fetch once locally, commit the CSV to your repo, and load from file as a backup.
Add retry logic â€” sometimes it works on a second attempt.
For a Euromoney demo, option 1 is the safest â€” you don't want a live API failure killing your presentation. Want me to add a built-in fallback dataset that kicks in automatically when yfinance is unavailable?

@st.cache_data(ttl=3600)
def get_market_data(tickers):
    data_list = []
    for t in tickers:
        try:
            stock = yf.Ticker(t)
            # Fetch beta from historical statistical analysis [cite: 24, 26]
            info = stock.info
            beta = info.get('beta', 1.0) 

            # Fetch 6-month historical data for Momentum [cite: 182]
            hist = stock.history(period="6mo")
            if hist.empty: raise ValueError("No hist data")

            momentum = ((hist['Close'].iloc[-1] / hist['Close'].iloc[0]) - 1) * 100

            # Use Ticker string to seed AI signals for consistency [cite: 137, 156]
            np.random.seed(sum(ord(c) for c in t)) 
            data_list.append({
                "Ticker": t, "Beta": round(beta, 2), 
                "Momentum": round(momentum, 2),
                "AI_Sentiment": round(np.random.uniform(-1, 1), 2),
                "XGB_Conviction": round(np.random.uniform(0.3, 0.95), 2),
                "Cluster": f"Group {np.random.choice([1, 2, 3, 4])}"
            })
        except Exception as e:
            # FALLBACK: Create synthetic data if API fails so the demo continues 
            np.random.seed(len(t))
            data_list.append({
                "Ticker": t, "Beta": np.random.uniform(0.5, 1.8), 
                "Momentum": np.random.uniform(-20, 20),
                "AI_Sentiment": np.random.uniform(-1, 1),
                "XGB_Conviction": np.random.uniform(0.5, 0.9),
                "Cluster": f"Group {np.random.randint(1,5)}"
            })
    return pd.DataFrame(data_list)

Show more
15:31
Good approach â€” the fallback inside the except block guarantees the demo always works. Let me integrate this into the current app. The same fallback logic needs to apply to get_price_history too, otherwise the charts will break even if the stock table loads.


Replace both data fetching functions with fallback-enabled versions
Now let me also add a small banner so the audience knows when they're seeing synthetic vs live data:


Edited a file, read a file
Two fallbacks now in place:

get_market_data â€” if yfinance fails for any ticker, it generates synthetic beta, momentum, sector, and AI signals using your pattern. No ticker ever gets skipped, so the table is always full.

get_price_history â€” if the bulk download fails, it generates a 126-day synthetic random walk per ticker. This means the correlation heatmap, cumulative return backtest, and all other charts still render even without network access.

There's also a small caption under the section header that tells the audience whether they're seeing live or synthetic data â€” important for a learning demo so nobody mistakes fake numbers for real market signals.

Emn portfolio builder
PY 


Next time, try this in Cowork

Hand off complex tasks for Claude to handle independently. Come back to finished results.

There is an issue in this program, it categorises stocks 


Claude is AI and can make mistakes. Please double-check responses.
Emn portfolio builder Â· PY
Copy

import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import plotly.express as px
import plotly.graph_objects as go
import logging

logging.basicConfig(level=logging.WARNING)
logger = logging.getLogger(__name__)

st.set_page_config(page_title="EMN AI Portfolio Builder", layout="wide")
st.title("ðŸš€ Equity Market Neutral (EMN) AI Portfolio Builder")


# ============================================================
# 1. DATA FETCHING
# ============================================================
@st.cache_data(ttl=3600)
def get_market_data(tickers: list[str]) -> pd.DataFrame:
    """Fetch stock metadata. Falls back to synthetic data if API fails."""
    data_list = []
    for t in tickers:
        try:
            stock = yf.Ticker(t)
            info = stock.info
            beta = info.get("beta", 1.0)
            if beta is None:
                beta = 1.0
            beta = float(beta)
            sector = info.get("sector", "Unknown")

            hist = stock.history(period="6mo")
            if hist.empty:
                raise ValueError("No hist data")
            momentum = ((hist["Close"].iloc[-1] / hist["Close"].iloc[0]) - 1) * 100

            np.random.seed(sum(ord(c) for c in t))
            data_list.append(
                {
                    "Ticker": t,
                    "Sector": sector,
                    "Beta": round(beta, 2),
                    "Momentum": round(momentum, 2),
                    "AI_Sentiment": round(np.random.uniform(-1, 1), 2),
                    "XGB_Conviction": round(np.random.uniform(0.3, 0.95), 2),
                    "Cluster": f"Group {np.random.choice([1, 2, 3, 4])}",
                }
            )
        except Exception as e:
            # FALLBACK: synthetic data so the demo always works
            logger.warning("API failed for %s (%s) â€” using synthetic data", t, e)
            np.random.seed(len(t))
            data_list.append(
                {
                    "Ticker": t,
                    "Sector": np.random.choice(
                        ["Technology", "Energy", "Financials", "Consumer", "Healthcare"]
                    ),
                    "Beta": round(np.random.uniform(0.5, 1.8), 2),
                    "Momentum": round(np.random.uniform(-20, 20), 2),
                    "AI_Sentiment": round(np.random.uniform(-1, 1), 2),
                    "XGB_Conviction": round(np.random.uniform(0.5, 0.9), 2),
                    "Cluster": f"Group {np.random.randint(1, 5)}",
                }
            )
    return pd.DataFrame(data_list)


@st.cache_data(ttl=3600)
def get_price_history(tickers: list[str], period: str = "6mo") -> pd.DataFrame:
    """Fetch daily close prices. Falls back to synthetic random walk if API fails."""
    if not tickers:
        return pd.DataFrame()
    try:
        data = yf.download(tickers, period=period, progress=False)["Close"]
        if isinstance(data, pd.Series):
            data = data.to_frame(name=tickers[0])
        if data.empty:
            raise ValueError("Empty price data")
        return data.dropna()
    except Exception as exc:
        # FALLBACK: generate synthetic price history so charts still work
        logger.warning("Price download failed (%s) â€” generating synthetic data", exc)
        np.random.seed(42)
        dates = pd.bdate_range(end=pd.Timestamp.today(), periods=126)
        prices = {}
        for t in tickers:
            np.random.seed(sum(ord(c) for c in t))
            base = np.random.uniform(50, 500)
            returns = np.random.normal(0.0005, 0.02, len(dates))
            prices[t] = base * np.cumprod(1 + returns)
        return pd.DataFrame(prices, index=dates)


UNIVERSE = [
    "AAPL", "TSLA", "XOM", "JPM", "MSFT",
    "META", "NVDA", "AMZN", "GOOGL", "BRK-B",
]
df_stocks = get_market_data(UNIVERSE)


# ============================================================
# 2. UNIVERSE DASHBOARD
# ============================================================
st.subheader("ðŸ“Š Stock Universe & AI Insights")
if df_stocks.empty:
    st.warning("No stock data could be loaded. Check your network / tickers.")
    st.stop()

# Indicate data source to the audience
_has_live = any(df_stocks["Sector"] != "Unknown") and not all(
    df_stocks["Sector"].isin(["Technology", "Energy", "Financials", "Consumer", "Healthcare"])
    & (df_stocks["Sector"].value_counts().max() <= 2)
)
if _has_live:
    st.caption("ðŸŸ¢ Live data from Yahoo Finance")
else:
    st.caption("ðŸŸ¡ Using synthetic demo data (Yahoo Finance unavailable)")

styled_df = (
    df_stocks.style.background_gradient(subset=["AI_Sentiment"], cmap="RdYlGn")
    .background_gradient(subset=["XGB_Conviction"], cmap="Greens")
    .format({"Momentum": "{:.2f}%", "XGB_Conviction": "{:.0%}"})
)
st.dataframe(styled_df, use_container_width=True, hide_index=True)


# ============================================================
# EDUCATION HUB
# ============================================================
with st.expander("ðŸ“š Guide: How to interpret AI Signals & Factors"):
    col_a, col_b = st.columns(2)
    with col_a:
        st.markdown("### ðŸ“ˆ Factor Definitions")
        st.write(
            "**Momentum (6-Mo):** Price trend over the last 180 days. "
            "High momentum identifies 'winners' likely to continue outperforming."
        )
        st.write(
            "**AI Sentiment:** NLP analysis of earnings calls and news. "
            "Scores range from -1 (Bearish) to +1 (Bullish)."
        )
    with col_b:
        st.markdown("### ðŸ¤– AI Model Logic")
        st.write(
            "**XGB Conviction:** Supervised learning probability (0-100%) "
            "that the stock will beat its peers."
        )
        st.write(
            "**Cluster Group:** Unsupervised clustering of stocks with similar "
            "behavior; diversify by picking from different groups."
        )
    st.divider()
    st.markdown("### ðŸ’° Exposure & Neutrality")
    col_c, col_d = st.columns(2)
    with col_c:
        st.write(
            "**Dollar Neutral (100/100):** Equal dollar amounts on each side â€” "
            "$1 long for every $1 short. Net dollar exposure = 0%."
        )
        st.write(
            "**Directional tilt (e.g. 130/30):** More capital on the long side "
            "means a net-long bias. Useful when you have higher conviction on longs "
            "but still want to hedge with shorts."
        )
    with col_d:
        st.write(
            "**Beta Neutral:** Weighted beta of longs equals weighted beta of shorts, "
            "so the portfolio has zero sensitivity to market direction. "
            "You can be dollar neutral but still market-exposed if betas differ."
        )
        st.write(
            "**Gross Exposure:** Total capital deployed (long% + short%). "
            "Higher gross = more leverage and risk."
        )
    st.info(
        "ðŸ’¡ **Strategy Tip:** Start at 100/100 for a classic market-neutral setup. "
        "Use the exposure slider to tilt directionally if you have a market view. "
        "Then adjust individual weights and aim for Net Beta â‰ˆ 0.00."
    )

st.divider()


# ============================================================
# 3. POSITION SELECTION (with overlap guard)
# ============================================================
available_tickers = df_stocks["Ticker"].tolist()

col_sel1, col_sel2 = st.columns(2)
with col_sel1:
    longs = st.multiselect("ðŸŸ¢ Select Long Positions", options=available_tickers, key="ls")
with col_sel2:
    short_options = [t for t in available_tickers if t not in longs]
    shorts = st.multiselect("ðŸ”´ Select Short Positions", options=short_options, key="ss")


# ============================================================
# 4. EXPOSURE CONTROLS
# ============================================================
st.subheader("ðŸ’° Exposure Configuration")

exp_col1, exp_col2, exp_col3 = st.columns(3)
with exp_col1:
    total_capital = st.number_input(
        "Total Capital ($)", min_value=10_000, max_value=100_000_000,
        value=1_000_000, step=100_000, format="%d", key="capital",
    )
with exp_col2:
    long_pct = st.slider(
        "Long Exposure (%)", min_value=0, max_value=200, value=100, step=5, key="long_pct",
    )
with exp_col3:
    short_pct = st.slider(
        "Short Exposure (%)", min_value=0, max_value=200, value=100, step=5, key="short_pct",
    )

long_notional = total_capital * long_pct / 100
short_notional = total_capital * short_pct / 100
gross_exposure = long_pct + short_pct
net_exposure = long_pct - short_pct

# Exposure summary
mc1, mc2, mc3, mc4 = st.columns(4)
mc1.metric("Long Notional", f"${long_notional:,.0f}")
mc2.metric("Short Notional", f"${short_notional:,.0f}")
mc3.metric("Gross Exposure", f"{gross_exposure}%")
mc4.metric("Net Dollar Exposure", f"{net_exposure:+d}%")

if net_exposure == 0:
    st.success("âœ… **Dollar Neutral** â€” equal notional on both sides")
elif abs(net_exposure) <= 20:
    st.warning(f"âš¡ **Slight directional tilt** â€” net {net_exposure:+d}% exposure")
else:
    st.error(f"ðŸŽ¯ **Directional portfolio** â€” net {net_exposure:+d}% exposure")

st.divider()


# ============================================================
# 5. WEIGHT SLIDERS
# ============================================================
st.subheader("âš–ï¸ Weight Allocation")


def collect_weights(tickers: list[str], side: str, notional: float) -> dict[str, float]:
    """Render sliders, return normalised weights summing to 1.0. Show dollar amounts."""
    if not tickers:
        st.info(f"Select {side} stocks above to begin.")
        return {}

    default = round(1.0 / len(tickers), 2)

    raw = {}
    cols = st.columns(len(tickers))
    for i, t in enumerate(tickers):
        with cols[i]:
            raw[t] = st.slider(f"{t}", 0.0, 1.0, default, 0.01, key=f"sl_{side}_{t}")

    total_raw = sum(raw.values())
    if total_raw > 0:
        normed = {t: v / total_raw for t, v in raw.items()}
    else:
        normed = {t: 1.0 / len(tickers) for t in tickers}

    # Show normalised weights + dollar allocation
    bar_cols = st.columns(len(tickers))
    for i, t in enumerate(tickers):
        with bar_cols[i]:
            pct = normed[t] * 100
            dollar = normed[t] * notional
            st.progress(min(normed[t], 1.0), text=f"{t}: {pct:.1f}%")
            st.caption(f"${dollar:,.0f}")

    return normed


col_l, col_r = st.columns(2)
with col_l:
    st.markdown(f"**ðŸŸ¢ Long Weights** (${long_notional:,.0f} total)")
    long_weights = collect_weights(longs, "long", long_notional)
with col_r:
    st.markdown(f"**ðŸ”´ Short Weights** (${short_notional:,.0f} total)")
    short_weights = collect_weights(shorts, "short", short_notional)


# ============================================================
# 6. PORTFOLIO METRICS
# ============================================================

def calc_beta(weights: dict[str, float], exposure_pct: float, data: pd.DataFrame) -> float:
    """Calculate weighted beta scaled by exposure percentage."""
    if not weights:
        return 0.0
    beta_lookup = data.set_index("Ticker")["Beta"]
    raw_beta = sum(w * beta_lookup.get(t, 1.0) for t, w in weights.items())
    return raw_beta * (exposure_pct / 100)


l_beta = calc_beta(long_weights, long_pct, df_stocks)
s_beta = calc_beta(short_weights, short_pct, df_stocks)
net_beta = l_beta - s_beta

st.divider()
c1, c2, c3 = st.columns(3)
c1.metric("Long Side Beta", round(l_beta, 3))
c2.metric("Short Side Beta", round(s_beta, 3))
c3.metric("NET PORTFOLIO BETA", round(net_beta, 3))

abs_beta = abs(net_beta)
if abs_beta <= 0.05:
    st.success(f"ðŸŸ¢ **Beta Neutral** (|Î²| = {abs_beta:.3f} â‰¤ 0.05) â€” fully hedged against market moves")
elif abs_beta <= 0.10:
    st.warning(f"ðŸŸ¡ **Near Neutral** (|Î²| = {abs_beta:.3f} â‰¤ 0.10) â€” minor directional exposure, acceptable for most EMN strategies")
elif abs_beta <= 0.20:
    st.warning(f"ðŸŸ  **Loosely Neutral** (|Î²| = {abs_beta:.3f} â‰¤ 0.20) â€” moderate market sensitivity, typical of low-beta long/short funds")
else:
    st.error(f"ðŸ”´ **Market Exposed** (|Î²| = {abs_beta:.3f} > 0.20) â€” significant directional risk, not market neutral")


# ============================================================
# 7. PORTFOLIO SUMMARY TABLE
# ============================================================
if long_weights or short_weights:
    st.divider()
    st.subheader("ðŸ“‹ Portfolio Summary")

    beta_lookup = df_stocks.set_index("Ticker")["Beta"]
    summary_rows = []

    for t, w in long_weights.items():
        b = beta_lookup.get(t, 1.0)
        dollar = w * long_notional
        beta_contrib = w * b * (long_pct / 100)
        summary_rows.append({
            "Ticker": t, "Side": "ðŸŸ¢ Long", "Weight": f"{w * 100:.1f}%",
            "Notional": f"${dollar:,.0f}", "Beta": b,
            "Beta Contribution": round(beta_contrib, 4),
        })
    for t, w in short_weights.items():
        b = beta_lookup.get(t, 1.0)
        dollar = w * short_notional
        beta_contrib = -w * b * (short_pct / 100)
        summary_rows.append({
            "Ticker": t, "Side": "ðŸ”´ Short", "Weight": f"{w * 100:.1f}%",
            "Notional": f"${dollar:,.0f}", "Beta": b,
            "Beta Contribution": round(beta_contrib, 4),
        })

    if summary_rows:
        summary_df = pd.DataFrame(summary_rows)
        st.dataframe(summary_df, use_container_width=True, hide_index=True)


# ============================================================
# 8. LIVE CHARTS
# ============================================================
all_selected = longs + shorts
if all_selected:
    st.divider()
    st.subheader("ðŸ“ˆ Portfolio Analytics (Live Data)")

    prices = get_price_history(all_selected)

    if not prices.empty:
        daily_returns = prices.pct_change().dropna()

        # --------------------------------------------------
        # CHART 1: Correlation Heatmap
        # --------------------------------------------------
        if len(all_selected) >= 2:
            st.markdown("#### ðŸ”— Correlation Matrix")
            st.caption(
                "Shows how selected stocks move together. "
                "For a good EMN portfolio, you want low correlation between long and short legs."
            )
            corr = daily_returns[all_selected].corr()

            fig_corr = px.imshow(
                corr,
                text_auto=".2f",
                color_continuous_scale="RdBu_r",
                zmin=-1, zmax=1,
                aspect="auto",
            )
            fig_corr.update_layout(height=400, margin=dict(l=20, r=20, t=30, b=20))
            st.plotly_chart(fig_corr, use_container_width=True)

        # --------------------------------------------------
        # CHART 2: Cumulative Return Backtest
        # --------------------------------------------------
        if long_weights and short_weights:
            st.markdown("#### ðŸ“Š Cumulative Return Backtest (6-Month)")
            st.caption(
                "Simulates how your portfolio would have performed with the current weights "
                "and exposure levels. The blue line is your net strategy return."
            )

            # Build weighted return series scaled by exposure
            long_ret = pd.Series(0.0, index=daily_returns.index)
            for t, w in long_weights.items():
                if t in daily_returns.columns:
                    long_ret += w * daily_returns[t] * (long_pct / 100)

            short_ret = pd.Series(0.0, index=daily_returns.index)
            for t, w in short_weights.items():
                if t in daily_returns.columns:
                    short_ret += w * daily_returns[t] * (short_pct / 100)

            # Net return: long profits minus short losses
            net_ret = long_ret - short_ret

            cum_long = (1 + long_ret).cumprod() - 1
            cum_short = (1 + short_ret).cumprod() - 1
            cum_net = (1 + net_ret).cumprod() - 1

            fig_cum = go.Figure()
            fig_cum.add_trace(go.Scatter(
                x=cum_long.index, y=cum_long * 100,
                name="Long Leg", line=dict(color="#2ecc71", width=2),
            ))
            fig_cum.add_trace(go.Scatter(
                x=cum_short.index, y=cum_short * 100,
                name="Short Leg", line=dict(color="#e74c3c", width=2),
            ))
            fig_cum.add_trace(go.Scatter(
                x=cum_net.index, y=cum_net * 100,
                name="Net (L âˆ’ S)", line=dict(color="#3498db", width=3),
            ))
            fig_cum.add_hline(y=0, line_dash="dash", line_color="grey", opacity=0.5)
            fig_cum.update_layout(
                yaxis_title="Cumulative Return (%)",
                xaxis_title="",
                height=420,
                margin=dict(l=20, r=20, t=30, b=20),
                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
            )
            st.plotly_chart(fig_cum, use_container_width=True)

            # Quick stats
            col_s1, col_s2, col_s3, col_s4 = st.columns(4)
            col_s1.metric("Long Leg Return", f"{cum_long.iloc[-1] * 100:+.2f}%")
            col_s2.metric("Short Leg Return", f"{cum_short.iloc[-1] * 100:+.2f}%")
            col_s3.metric("Net Strategy Return", f"{cum_net.iloc[-1] * 100:+.2f}%")
            # Dollar P&L
            net_pnl = cum_net.iloc[-1] * total_capital
            col_s4.metric("Net P&L", f"${net_pnl:+,.0f}")

        # --------------------------------------------------
        # CHART 3: Beta Contribution Waterfall
        # --------------------------------------------------
        if long_weights or short_weights:
            st.markdown("#### ðŸ“ Beta Contribution by Position")
            st.caption(
                "Each bar shows how much beta a position contributes (scaled by exposure). "
                "The goal is for the green (long) bars to offset the red (short) bars."
            )

            beta_lookup = df_stocks.set_index("Ticker")["Beta"]
            waterfall_data = []

            for t, w in long_weights.items():
                b = beta_lookup.get(t, 1.0)
                waterfall_data.append({
                    "Ticker": f"{t} (L)",
                    "Beta Contribution": round(w * b * (long_pct / 100), 4),
                    "Side": "Long",
                })
            for t, w in short_weights.items():
                b = beta_lookup.get(t, 1.0)
                waterfall_data.append({
                    "Ticker": f"{t} (S)",
                    "Beta Contribution": round(-w * b * (short_pct / 100), 4),
                    "Side": "Short",
                })

            if waterfall_data:
                wf_df = pd.DataFrame(waterfall_data)
                colors = ["#2ecc71" if s == "Long" else "#e74c3c" for s in wf_df["Side"]]

                fig_wf = go.Figure(go.Bar(
                    x=wf_df["Ticker"], y=wf_df["Beta Contribution"],
                    marker_color=colors,
                    text=[f"{v:+.3f}" for v in wf_df["Beta Contribution"]],
                    textposition="outside",
                ))
                fig_wf.add_hline(y=0, line_color="grey", line_width=1)
                fig_wf.add_annotation(
                    x=1.0, y=1.0, xref="paper", yref="paper",
                    text=f"Net Beta: {net_beta:+.3f}",
                    showarrow=False,
                    font=dict(size=14, color="#3498db"),
                    bgcolor="white", bordercolor="#3498db", borderwidth=1, borderpad=6,
                )
                fig_wf.update_layout(
                    yaxis_title="Beta Contribution",
                    xaxis_title="", height=400,
                    margin=dict(l=20, r=20, t=30, b=20),
                    showlegend=False,
                )
                st.plotly_chart(fig_wf, use_container_width=True)

        # --------------------------------------------------
        # CHART 4: Sector Exposure
        # --------------------------------------------------
        if long_weights or short_weights:
            st.markdown("#### ðŸ­ Sector Exposure")
            st.caption(
                "Net dollar exposure by sector. "
                "Even a beta-neutral portfolio can have concentrated sector risk."
            )

            sector_lookup = df_stocks.set_index("Ticker")["Sector"]
            sector_exposure = {}

            for t, w in long_weights.items():
                sec = sector_lookup.get(t, "Unknown")
                sector_exposure[sec] = sector_exposure.get(sec, 0) + w * long_notional

            for t, w in short_weights.items():
                sec = sector_lookup.get(t, "Unknown")
                sector_exposure[sec] = sector_exposure.get(sec, 0) - w * short_notional

            if sector_exposure:
                sec_df = pd.DataFrame(
                    [{"Sector": k, "Net Exposure ($)": v} for k, v in sector_exposure.items()]
                ).sort_values("Net Exposure ($)")

                colors_sec = [
                    "#2ecc71" if v >= 0 else "#e74c3c" for v in sec_df["Net Exposure ($)"]
                ]

                fig_sec = go.Figure(go.Bar(
                    x=sec_df["Net Exposure ($)"],
                    y=sec_df["Sector"],
                    orientation="h",
                    marker_color=colors_sec,
                    text=[f"${v:+,.0f}" for v in sec_df["Net Exposure ($)"]],
                    textposition="outside",
                ))
                fig_sec.add_vline(x=0, line_color="grey", line_width=1)
                fig_sec.update_layout(
                    xaxis_title="Net Exposure ($)",
                    yaxis_title="",
                    height=max(250, len(sector_exposure) * 50),
                    margin=dict(l=20, r=20, t=30, b=20),
                )
                st.plotly_chart(fig_sec, use_container_width=True)

    else:
        st.warning("Could not load price history for selected stocks.")
else:
    st.info("Select long and short positions above to see portfolio analytics.")